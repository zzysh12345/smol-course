{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-6LLOPZouLg"
   },
   "source": [
    "# Hugging Face TRLê³¼ LoRA ì–´ëŒ‘í„°ë¥¼ í™œìš©í•´ LLMì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” LoRA(Low-Rank Adaptation) ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. LoRAëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§€ëŠ” íŒŒë¼ë¯¸í„° íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì • ê¸°ë²•ì…ë‹ˆë‹¤:\n",
    "- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì •\n",
    "- ì–´í…ì…˜ ë ˆì´ì–´ì— í•™ìŠµ ê°€ëŠ¥í•œ ì €ë­í¬ ë¶„í•´ í–‰ë ¬ ì¶”ê°€\n",
    "- í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ìµœëŒ€ 90%ê¹Œì§€ ê°ì†Œ\n",
    "- ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ì„œ ëª¨ë¸ ì„±ëŠ¥ ìœ ì§€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤:\n",
    "1. ê°œë°œ í™˜ê²½ ë° LoRA configuration ì„¤ì •\n",
    "2. ì–´ëŒ‘í„° í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ìƒì„± ë° ì¤€ë¹„\n",
    "3. `trl`ê³¼ `SFTTrainer`ë¥¼ í™œìš©í•œ LoRA ì–´ëŒ‘í„° ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì •\n",
    "4. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì–´ëŒ‘í„° ë³‘í•©(ì„ íƒ ì‚¬í•­)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXqd9BXgouLi"
   },
   "source": [
    "## 1. ê°œë°œ í™˜ê²½ ì„¤ì •\n",
    "\n",
    "ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” trl, transformers, datasetsì„ í¬í•¨í•œ Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Pytorchë¥¼ ì„¤ì¹˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. trlì„ ë“¤ì–´ë³¸ ì ì´ ì—†ë”ë¼ë„ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”. trlì€ transformersì™€ datasets ìœ„ì— êµ¬ì¶•ëœ ìƒˆë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì˜¤í”ˆ ì†ŒìŠ¤ LLMì˜ ë¯¸ì„¸ ì¡°ì •ê³¼ RLHF, ì •ë ¬ ì‘ì—…ì„ ì‰½ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKvGVxImouLi"
   },
   "outputs": [],
   "source": [
    "# Google Colabì—ì„œ requirements ì„¤ì¹˜\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Hugging Face ì¸ì¦\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# í—ˆë¸Œ í† í°ì„ HF_TOKEN í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ë‘ë©´ í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHUzfwpKouLk"
   },
   "source": [
    "## 2. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z4p6Bvo7ouLk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì˜ˆì‹œ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: pathì™€ name íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•´ ì›í•˜ëŠ” ë°ì´í„°ì…‹ ì •ì˜í•˜ê¸°\n",
    "dataset = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TOhJdtsouLk"
   },
   "source": [
    "## 3. LoRAì™€ í•¨ê»˜ `trl`ê³¼ `SFTTrainer`ë¥¼ ì‚¬ìš©í•œ LLM ë¯¸ì„¸ ì¡°ì •\n",
    "\n",
    "`trl`ì—ì„œ ì œê³µí•˜ëŠ” [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)ëŠ” [PEFT](https://huggingface.co/docs/peft/en/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ LoRA ì–´ëŒ‘í„°ì™€ì˜ í†µí•©ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì„¤ì •ì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: \n",
    "   - GPU ë©”ëª¨ë¦¬ì— ì–´ëŒ‘í„° íŒŒë¼ë¯¸í„°ë§Œ ì €ì¥\n",
    "   - ê¸°ë³¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” ê³ ì •ë˜ë©° ë” ë‚®ì€ ì •ë°€ë„ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° ê°€ëŠ¥\n",
    "   - ì„œë²„ê°€ ì•„ë‹Œ ì†Œë¹„ììš© GPUì—ì„œ ëŒ€í˜• ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ê°€ëŠ¥\n",
    "\n",
    "2. **í•™ìŠµ ê¸°ëŠ¥**:\n",
    "   - ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ PEFT/LoRA í†µí•©\n",
    "   - ë” ë‚˜ì€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ QLoRA(ì–‘ìí™”ëœ LoRA) ì§€ì›\n",
    "\n",
    "3. **ì–´ëŒ‘í„° ê´€ë¦¬**:\n",
    "   - ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ë„ ì €ì¥\n",
    "   - ì–´ëŒ‘í„°ë¥¼ ê¸°ë³¸ ëª¨ë¸ì— ë³‘í•©í•˜ëŠ” ê¸°ëŠ¥ ì œê³µ\n",
    "\n",
    "ì´ë²ˆ ì˜ˆì œì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜ ì—†ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë”ìš± ì¤„ì´ê¸° ìœ„í•´ 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ê²°í•©í•œ LoRAë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤. ì„¤ì •ì€ ëª‡ ê°€ì§€ ë‹¨ê³„ë§Œ ê±°ì¹˜ë©´ ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. LoRA configuration ì„¤ì •(ë­í¬, ì•ŒíŒŒ, ë“œë¡­ì•„ì›ƒ)\n",
    "2. PEFT configurationì„ ì¶”ê°€í•œ SFTTrainer ìƒì„±\n",
    "3. ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ í•™ìŠµ ë° ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# ëŒ€í™” í˜•ì‹ ì„¤ì •\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ë¯¸ì„¸ ì¡°ì • ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ì—…ë¡œë“œí•˜ê¸° ìœ„í•œ ì´ë¦„ ì„¤ì •\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbuVArTHouLk"
   },
   "source": [
    "`SFTTrainer`ëŠ” `peft`ì™€ì˜ ê¸°ë³¸ í†µí•©ì„ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— LoRAì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ LLM ë¯¸ì„¸ ì¡°ì • ì‘ì—…ì„ ë§¤ìš° ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” `LoraConfig`ë¥¼ ìƒì„±í•˜ê³  íŠ¸ë ˆì´ë„ˆì—ê²Œ ì œê³µí•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ì—°ìŠµ: ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ LoRA íŒŒë¼ë¯¸í„° ì •ì˜í•˜ê¸°</h2>\n",
    "    <p>Hugging Face í—ˆë¸Œì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì • í•´ë³´ì„¸ìš”.</p> \n",
    "    <p><b>ë‚œì´ë„</b></p>\n",
    "    <p>ğŸ¢ ì¼ë°˜ì ì¸ íŒŒë¼ë¯¸í„° ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì„ì˜ë¡œ ë¯¸ì„¸ ì¡°ì • ì§„í–‰í•˜ê¸°</p>\n",
    "    <p>ğŸ• íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê³  ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ê²€í† í•´ë³´ê¸°</p>\n",
    "    <p>ğŸ¦ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê³  ì¶”ë¡  ê²°ê³¼ ë³€í™” í™•ì¸í•˜ê¸°</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blDSs9swouLk"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# TODO: LoRA íŒŒë¼ë¯¸í„°ë¥¼ êµ¬ì„±í•´ë³´ì„¸ìš”.\n",
    "# r: LoRA ì—…ë°ì´íŠ¸ í–‰ë ¬ì„ ìœ„í•œ ë­í¬ ì°¨ì›ì› (ì‘ì„ìˆ˜ë¡ ì••ì¶•ë¥ ì´ ë†’ì•„ì§)\n",
    "rank_dimension = 6\n",
    "# lora_alpha: LoRA ë ˆì´ì–´ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜ (ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ì˜ ì ì‘í•¨)\n",
    "lora_alpha = 8\n",
    "# lora_dropout: LoRA ë ˆì´ì–´ì˜ ë“œë¡­ì•„ì›ƒ í™•ë¥  (ê³¼ì í•© ë°©ì§€)\n",
    "lora_dropout = 0.05\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=rank_dimension,  # ë­í¬ ì°¨ì› - ì¼ë°˜ì ìœ¼ë¡œ 4-32 ì‚¬ì´ì˜ ê°’ ì‚¬ìš©\n",
    "    lora_alpha=lora_alpha,  # LoRA ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜ - ì¼ë°˜ì ìœ¼ë¡œ ë­í¬ ì°¨ì›ì˜ 2ë°°\n",
    "    lora_dropout=lora_dropout,  # LoRA ë ˆì´ì–´ì˜ì˜ ë“œë¡­ì•„ì›ƒ í™•ë¥ \n",
    "    bias=\"none\",  # LoRA í¸í–¥ ìœ í˜• - í•´ë‹¹ í¸í–¥ì€ í•™ìŠµ ì¤‘ ì—…ë°ì´íŠ¸ë¨ë¨\n",
    "    target_modules=\"all-linear\",  # LoRAë¥¼ ì ìš©í•  ëª¨ë“ˆë“ˆ\n",
    "    task_type=\"CAUSAL_LM\",  # ëª¨ë¸ êµ¬ì¡°ì— ë§ëŠ” íƒœìŠ¤í¬ ìœ í˜•\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5NUDPcaouLl"
   },
   "source": [
    "í•™ìŠµì„ ì‹œì‘í•˜ê¸° ì „ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°(`TrainingArguments`) ê°’ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqT28VZlouLl"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ configuration\n",
    "# QLoRA ë…¼ë¬¸ì— ê¸°ë°˜í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "args = SFTConfig(\n",
    "    # ì¶œë ¥ ì„¤ì •\n",
    "    output_dir=finetune_name,  # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    # í•™ìŠµ ê¸°ê°„\n",
    "    num_train_epochs=1,  # í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "    # ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
    "    per_device_train_batch_size=2,  # GPUë‹¹ ë°°ì¹˜ í¬ê¸°\n",
    "    gradient_accumulation_steps=2,  # ë” í° ë°°ì¹˜ í¬ê¸° íš¨ê³¼ë¥¼ ìœ„í•œ ê²½ì‚¬ ëˆ„ì \n",
    "    # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    gradient_checkpointing=True,  # í•™ìŠµ ì†ë„ëŠ” ëŠë ¤ì§€ì§€ë§Œ ë©”ëª¨ë¦¬ ì ˆì•½ ê°€ëŠ¥\n",
    "    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "    optim=\"adamw_torch_fused\",  # íš¨ìœ¨ì„±ì„ ìœ„í•´ fused AdamW ì‚¬ìš©\n",
    "    learning_rate=2e-4,  # í•™ìŠµë¥  (QLoRA ë…¼ë¬¸ ì°¸ê³ )\n",
    "    max_grad_norm=0.3,  # ê²½ì‚¬ í´ë¦¬í•‘ ì„ê³—ê°’\n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§\n",
    "    warmup_ratio=0.03,  # í•™ìŠµë¥ ì„ 0ì—ì„œ ëª©í‘œ ê°’ê¹Œì§€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” ì›œì—…ì„ ìœ„í•œ ì „ì²´ í•™ìŠµ ìŠ¤í…ì˜ ë¹„ìœ¨\n",
    "    lr_scheduler_type=\"constant\",  # ì›œì—… í›„ ì¼ì •í•œ í•™ìŠµë¥  ìœ ì§€\n",
    "    # ë¡œê¹… ë° ì €ì¥\n",
    "    logging_steps=10,  # ë§¤ N ìŠ¤í…ë§ˆë‹¤ ì§€í‘œ ê¸°ë¡\n",
    "    save_strategy=\"epoch\",  # ë§¤ ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    # ì •ë°€ë„ ì„¤ì •\n",
    "    bf16=True,  # bfloat16 ì •ë°€ë„ ì‚¬ìš©\n",
    "    # í†µí•© ì„¤ì •\n",
    "    push_to_hub=False,  # Hugging Face í—ˆë¸Œë¡œ ë‚´ë³´ë‚´ì§€ ì•ŠìŒ\n",
    "    report_to=\"none\",  # ì™¸ë¶€ ë¡œê¹… ë¹„í™œì„±í™”\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGhR7uFBouLl"
   },
   "source": [
    "ì´ì œ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ `SFTTrainer` ìƒì„±ì— í•„ìš”í•œ ìš”ì†Œë¥¼ ëª¨ë‘ ê°–ì·„ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M00Har2douLl"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 1512  # ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ íŒ¨í‚¹ì„ ìœ„í•œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "\n",
    "# LoRA configurationìœ¼ë¡œ SFTTrainer ìƒì„±\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    peft_config=peft_config,  # LoRA configuration\n",
    "    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,  # íš¨ìœ¨ì„±ì„ ìœ„í•´ ì…ë ¥ íŒ¨í‚¹ í™œì„±í™”\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,  # í…œí”Œë¦¿ì—ì„œ ì¶”ê°€ í† í° ì²˜ë¦¬\n",
    "        \"append_concat_token\": False,  # ì¶”ê°€ êµ¬ë¶„ì ì—†ìŒ\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ_kRN24ouLl"
   },
   "source": [
    "`Trainer` ê°ì²´ì˜ `train()` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. í•™ìŠµ ë£¨í”„ê°€ ì‹œì‘ë˜ê³  3 ì—í¬í¬ ë™ì•ˆ ëª¨ë¸ì´ í•™ìŠµë©ë‹ˆë‹¤. ì§€ê¸ˆì€ PEFT ë°©ë²•ì„ ì“°ê³  ìˆê¸° ë•Œë¬¸ì— ì „ì²´ ëª¨ë¸ì„ ì €ì¥í•˜ì§€ ì•Šê³  ì ì‘ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq4nIYqKouLl"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e5dfbb4b54750b77324345c7591f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=72, training_loss=1.6402628521124523, metrics={'train_runtime': 195.2398, 'train_samples_per_second': 1.485, 'train_steps_per_second': 0.369, 'total_flos': 282267289092096.0, 'train_loss': 1.6402628521124523, 'epoch': 0.993103448275862})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµì´ ì‹œì‘ë˜ë©´ í—ˆë¸Œì™€ ì¶œë ¥ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ ìë™ ì €ì¥\n",
    "trainer.train()\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4HHSYYzouLl"
   },
   "source": [
    "`g5.2xlarge` ì¸ìŠ¤í„´ìŠ¤ì—ì„œ í”Œë˜ì‹œ ì–´í…ì…˜ì„ ì ìš©í•´ 15,000ê°œì˜ ìƒ˜í”Œì„ 3 ì—í¬í¬ ë™ì•ˆ í•™ìŠµí•˜ëŠ” ë° ê±¸ë¦° ì‹œê°„ì€ 4ì‹œê°„ 14ë¶„ 36ì´ˆì˜€ìŠµë‹ˆë‹¤. í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤ ë¹„ìš©ì€ ì‹œê°„ë‹¹ 1.21ë‹¬ëŸ¬ë¡œ, ì´ ë¹„ìš©ì€ ì•½ `5.3ë‹¬ëŸ¬`ì— ë¶ˆê³¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C309KsXjouLl"
   },
   "source": [
    "### ê¸°ì¡´ ëª¨ë¸ê³¼ LoRA ì–´ëŒ‘í„° ë³‘í•©\n",
    "\n",
    "LoRAë¥¼ ì‚¬ìš©í•  ë•Œ ê¸°ë³¸ ëª¨ë¸ì€ ê³ ì •ëœ ìƒíƒœë¡œ ë‘ê³  ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ë§Œ í•™ìŠµí•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ì „ì²´ ëª¨ë¸ì´ ì•„ë‹Œ 2-10MB í¬ê¸°ì˜ ê°€ë²¼ìš´ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ë§Œ ì €ì¥í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë°°í¬í•  ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì–´ëŒ‘í„°ë¥¼ ê¸°ë³¸ ëª¨ë¸ê³¼ ë³‘í•©í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ê°„ì†Œí™”ëœ ë°°í¬**: ê¸°ë³¸ ëª¨ë¸ê³¼ ì–´ëŒ‘í„°ë¥¼ ë”°ë¡œ ê´€ë¦¬í•˜ì§€ ì•Šê³  ë‹¨ì¼ ëª¨ë¸ë¡œ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "2. **ì¶”ë¡  ì†ë„**: ì–´ëŒ‘í„° ê³„ì‚°ì— ë”°ë¥¸ ì¶”ê°€ì ì¸ ì˜¤ë²„í—¤ë“œ ì—†ìŒ\n",
    "3. **í”„ë ˆì„ì›Œí¬ í˜¸í™˜ì„±**: ì„œë¹™ í”„ë ˆì„ì›Œí¬ì™€ì˜ í˜¸í™˜ì„± í–¥ìƒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "\n",
    "# CPUì—ì„œ PEFT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=args.output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# LoRAì™€ ê¸°ë³¸ ëª¨ë¸ ë³‘í•© í›„ ì €ì¥\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\n",
    "    args.output_dir, safe_serialization=True, max_shard_size=\"2GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yO6E9quouLl"
   },
   "source": [
    "## 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì¶”ë¡  ìˆ˜í–‰\n",
    "\n",
    "í•™ìŠµì´ ëë‚œ í›„ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ í•  ê²ƒì…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì–‘í•œ ì˜ˆì œë¥¼ ë¶ˆëŸ¬ì˜¨ ë’¤, í•´ë‹¹ ì˜ˆì œë¥¼ í™œìš©í•œ ê°„ë‹¨í•œ ë£¨í”„ì—ì„œ ì •í™•ë„ë¥¼ í‰ê°€ ì§€í‘œë¡œ ì‚¼ì•„ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ì¶”ê°€ ì—°ìŠµ: LoRA ì–´ëŒ‘í„° ë¶ˆëŸ¬ì˜¤ê¸°</h2>\n",
    "    <p>ì˜ˆì œ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ í™œìš©í•˜ì—¬ í•™ìŠµëœ LoRA ì–´ëŒ‘í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì¶”ë¡ ì— ì‚¬ìš©í•˜ì„¸ìš”.</p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "I5B494OdouLl"
   },
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ í™•ë³´\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1UhohVdouLl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# PEFT ì–´ëŒ‘í„°ê°€ ìˆëŠ” ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetune_name)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    finetune_name, device_map=\"auto\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=merged_model, tokenizer=tokenizer, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99uFDAuuouLl"
   },
   "source": [
    "ëª‡ ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì˜ˆì œë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ê³  ëª¨ë¸ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-shSmUbvouLl",
    "outputId": "16d97c61-3b31-4040-c780-3c4de75c3824"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the capital of Germany? Explain why thats the case and if it was different in the past?\",\n",
    "    \"Write a Python function to calculate the factorial of a number.\",\n",
    "    \"A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\",\n",
    "    \"What is the difference between a fruit and a vegetable? Give examples of each.\",\n",
    "]\n",
    "\n",
    "\n",
    "def test_inference(prompt):\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(prompt)}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
