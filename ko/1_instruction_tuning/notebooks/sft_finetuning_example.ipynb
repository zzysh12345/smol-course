{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFTTrainerë¥¼ í™œìš©í•œ ì§€ë„ í•™ìŠµ ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì •\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ `trl` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” `SFTTrainer`ë¥¼ ì´ìš©í•´ `HuggingFaceTB/SmolLM2-135M` ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë…¸íŠ¸ë¶ ì…€ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ ë¯¸ì„¸ ì¡°ì •ë©ë‹ˆë‹¤. ë‹¤ë¥¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ë‚œì´ë„ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ì—°ìŠµ: SFTTrainerë¥¼ í™œìš©í•œ SmolLM2 ë¯¸ì„¸ ì¡°ì •</h2>\n",
    "    <p>Hugging Face í—ˆë¸Œì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì€ ë¯¸ì„¸ ì¡°ì •í•´ë³´ì„¸ìš”. </p> \n",
    "    <p><b>ë‚œì´ë„</b></p>\n",
    "    <p>ğŸ¢ `HuggingFaceTB/smoltalk` ë°ì´í„°ì…‹ ì‚¬ìš©í•´ë³´ê¸°</p>\n",
    "    <p>ğŸ• `bigcode/the-stack-smol` ë°ì´í„°ì…‹ì˜ í•˜ìœ„ ì§‘í•©ì¸ `data/python`ì„ í™œìš©í•´ ì½”ë“œ ìƒì„± ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •í•´ë³´ê¸°</p>\n",
    "    <p>ğŸ¦ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ì™€ ê´€ë ¨ëœ ê´€ì‹¬ ìˆëŠ” ë°ì´í„°ì…‹ ì‚¬ìš©í•´ë³´ê¸°</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabì—ì„œ requirements ì„¤ì¹˜\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Hugging Face ì¸ì¦\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "# í—ˆë¸Œ í† í°ì„ HF_TOKEN í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ë‘ë©´ í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# ëŒ€í™” í˜•ì‹ ì„¤ì •\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ë¯¸ì„¸ ì¡°ì • ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ì—…ë¡œë“œí•˜ê¸° ìœ„í•œ ì´ë¦„ ì„¤ì •\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê¸°ë³¸ ëª¨ë¸ì„ í™œìš©í•œ ë‹µë³€ ìƒì„±\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ëŒ€í™” í…œí”Œë¦¿ì´ ì—†ëŠ” ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì „ ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì§„í–‰\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# í…œí”Œë¦¿ìœ¼ë¡œ ë©”ì‹œì§€ í˜•ì‹ ì§€ì •\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# ì‘ë‹µ ìƒì„±\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "\n",
    "ìƒ˜í”Œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµì„ ìœ„í•œ í˜•ì‹ì„ ì§€ì •í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ì…ë ¥-ì¶œë ¥ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•˜ë©°, ê° ì…ë ¥ì€ í”„ë¡¬í”„íŠ¸ì´ê³  ì¶œë ¥ì€ ëª¨ë¸ì—ì„œ ì˜ˆìƒë˜ëŠ” ì‘ë‹µì…ë‹ˆë‹¤. **TRLì€ ëª¨ë¸ì˜ ëŒ€í™” í…œí”Œë¦¿ì— ë§ê²Œ ì…ë ¥ ë©”ì‹œì§€ í˜•ì‹ì„ ë§ì¶¥ë‹ˆë‹¤.** ë©”ì‹œì§€ëŠ” `role`ê³¼ `content` í‚¤ë¥¼ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: pathì™€ name íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ê³¼ configuration ì •ì˜í•˜ê¸°\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ğŸ¦ ë°ì´í„°ì…‹ì´ TRLì—ì„œ ëŒ€í™” í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆëŠ” í˜•ì‹ì´ ì•„ë‹ˆë¼ë©´, í•´ë‹¹ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ëª¨ë“ˆ](../chat_templates.md)ì„ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFTTrainer ì„¤ì •\n",
    "\n",
    "`SFTTrainer`ëŠ” í•™ìŠµ ë‹¨ê³„ ìˆ˜, ë°°ì¹˜ í¬ê¸°, í•™ìŠµë¥ , í‰ê°€ ë°©ì‹ê³¼ ê°™ì´ í•™ìŠµ ê³¼ì •ì„ ì œì–´í•˜ëŠ” ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. íŠ¹ì • ìš”êµ¬ ì‚¬í•­ê³¼ ì—°ì‚° ìì›ì— ë§ì¶° íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFTTrainerë¥¼ ìœ„í•œ SFT configuration ì„¤ì •\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # ì›í•˜ëŠ” í•™ìŠµ ì‹œê°„ê³¼ ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼ ì¡°ì •\n",
    "    per_device_train_batch_size=4,  # GPU ë©”ëª¨ë¦¬ ìš©ëŸ‰ì— ë”°ë¼ ì„¤ì •\n",
    "    learning_rate=5e-5,  # ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œ ì“°ì´ëŠ” ê°’\n",
    "    logging_steps=10,  # í•™ìŠµ ì§€í‘œ ë¡œê¹… ë¹ˆë„\n",
    "    save_steps=100,  # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¹ˆë„\n",
    "    evaluation_strategy=\"steps\",  # ì£¼ê¸°ì ì¸ ëª¨ë¸ í‰ê°€ ì„¤ì •\n",
    "    eval_steps=50,  # í‰ê°€ ë¹ˆë„\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # í˜¼í•© ì •ë°€ë„ í•™ìŠµ(mixed precision training)ì„ ìœ„í•œ MPS ì‚¬ìš©\n",
    "    hub_model_id=finetune_name,  # ëª¨ë¸ ì´ë¦„ ì„¤ì •\n",
    ")\n",
    "\n",
    "# SFTTrainer ì´ˆê¸°í™”\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "# TODO: ğŸ¦ ğŸ• ì„ íƒí•œ ë°ì´í„°ì…‹ì— ë§ê²Œ SFTTrainer íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, `bigcode/the-stack-smol` ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° `content` ì—´ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "íŠ¸ë ˆì´ë„ˆê°€ êµ¬ì„±ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ì œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì€ ë°ì´í„°ì…‹ì„ ë°˜ë³µì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©° ì†ì‹¤ì„ ê³„ì‚°í•˜ê³ , ì´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "trainer.train()\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>ì¶”ê°€ ì—°ìŠµ: ë¯¸ì„¸ ì¡°ì • ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±í•˜ê¸°</h2>\n",
    "    <p>ğŸ• ê¸°ë³¸ ì˜ˆì œì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•´ë³´ì„¸ìš”.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.\n",
    "\n",
    "# í•™ìŠµ ì „ ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì§„í–‰\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# í…œí”Œë¦¿ìœ¼ë¡œ ë©”ì‹œì§€ í˜•ì‹ ì§€ì •\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# ì‘ë‹µ ìƒì„±\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: ê¸°ë³¸ ì˜ˆì œì—ì„œ í–ˆë˜ ê²ƒì²˜ëŸ¼ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‘ë‹µì„ ìƒì„±í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’ ì™„ë£Œ!\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ `SFTTrainer`ë¥¼ ì‚¬ìš©í•˜ì—¬ `HuggingFaceTB/SmolLM2-135M` ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ë¥¼ ë”°ë¼ íŠ¹ì • ì‘ì—…ì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë„ë¡ ëª¨ë¸ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ ê³„ì† ì§„í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”:\n",
    "\n",
    "- ë” ì–´ë ¤ìš´ ë°©ë²•ìœ¼ë¡œ ë…¸íŠ¸ë¶ ì‹¤ìŠµí•´ë³´ê¸°\n",
    "- ë™ë£Œì˜ PR ê²€í† í•˜ê¸°\n",
    "- ì´ìŠˆ ë˜ëŠ” PRì„ í†µí•´ ìë£Œ ê°œì„ í•˜ê¸°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
