{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hu·∫•n luy·ªán c√≥ gi√°m s√°t v·ªõi SFTTrainer\n",
    "\n",
    "B√†i h·ªçc n√†y se d·∫°y b·∫°n c√°c hu·∫•n luy·ªán m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` b·∫±ng `SFTTrainer` trong th∆∞ vi·ªán `trl`.  C√°c cell trong notebook n√†y s·∫Ω ch·∫°y v√† hu·∫•n luy·ªán m√¥ h√¨nh. B·∫°n c√≥ th·ªÉ ch·ªçn ƒë·ªô kh√≥ b·∫±ng c√°ch th·ª≠ nghi·ªám v·ªõi c√°c b·ªô d·ªØ li·ªáu kh√°c nhau.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p: Fine-Tuning SmolLM2 v·ªõi SFTTrainer</h2>\n",
    "    <p>Ch·ªçn m·ªôt b·ªô d·ª± li·ªáu t·ª´ Hugging Face hub v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh tr√™n b·ªô d·ªØ li·ªáu ƒë√≥. </p> \n",
    "    <p><b>C√°c b√†i t·∫≠p</b></p>\n",
    "    <p>üê¢ S·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu `HuggingFaceTB/smoltalk`</p>\n",
    "    <p>üêï Th·ª≠ nghi·ªám v·ªõi b·ªô d·ªØ li·ªáu `bigcode/the-stack-smol` v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh sinh code tr√™n t·∫≠p con c·ª• th·ªÉ `data/python`.</p>\n",
    "    <p>ü¶Å Ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu li√™n quan ƒë·∫øn m·ªôt lƒ©nh v·ª±c m√† b·∫°n quan t√¢m</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# ƒêƒÉng nh·∫≠p v√†o Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# ƒê·ªÉ thu·∫≠n ti·ªán, b·∫°n c√≥ th·ªÉ t·∫°o m·ªôt bi·∫øn m√¥i tr∆∞·ªùng ch·ª©a `token hub` c·ªßa b·∫°n d∆∞·ªõi d·∫°ng HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh v√† tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Thi·∫øt l·∫≠p ƒë·ªãnh d·∫°ng chat\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ƒê·∫∑t t√™n cho m√¥ h√¨nh hu·∫•n luy·ªán ƒë·ªÉ l∆∞u &/ t·∫£i l√™n\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinh vƒÉn b·∫£n v·ªõi M√¥ h√¨nh g·ªëc\n",
    "\n",
    "·ªû ƒë√¢y ch√∫ng ta s·∫Ω th·ª≠ nghi·ªám m√¥ h√¨nh g·ªëc ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n ƒë·ªãnh d·∫°ng chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# T·∫°o ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "\n",
    "Ch√∫ng ta s·∫Ω t·∫£i m·ªôt b·ªô d·ªØ li·ªáu m·∫´u v√† ƒë·ªãnh d·∫°ng n√≥ cho vi·ªác hu·∫•n luy·ªán. B·ªô d·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c c·∫•u tr√∫c v·ªõi c√°c c·∫∑p ƒë·∫ßu v√†o - ƒë·∫ßu ra, trong ƒë√≥ m·ªói ƒë·∫ßu v√†o l√† m·ªôt ch·ªâ th·ªã v√† ƒë·∫ßu ra l√† ph·∫£n h·ªìi mong ƒë·ª£i t·ª´ m√¥ h√¨nh.\n",
    "\n",
    "**TRL s·∫Ω ƒë·ªãnh d·∫°ng c√°c tin nh·∫Øn ƒë·∫ßu v√†o d·ª±a tr√™n ƒë·ªãnh d·∫°ng chat c·ªßa m√¥ h√¨nh** Ch√∫ng c·∫ßn ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng danh s√°ch c√°c t·ª´ ƒëi·ªÉn v·ªõi c√°c kh√≥a: `role` v√† `content`.\n",
    "\n",
    "**V√≠ d·ª•:**\n",
    "```sh\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I assist you today?\",},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫£i d·ªØ li·ªáu m·∫´u\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: T·∫£i b·ªô d·ªØ li·ªáu th√¥ng qua vi·ªác ƒëi·ªÅu ch·ªânh c√°c tham s·ªë path v√† name\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ü¶Å N·∫øu dataset c·ªßa b·∫°n kh√¥ng ·ªü ƒë·ªãnh d·∫°ng m√† TRL c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªãnh d·∫°ng chat, b·∫°n s·∫Ω c·∫ßn x·ª≠ l√Ω n√≥.\n",
    "# Tham kh·∫£o [ƒê·ªãnh d·∫°ng Chat](../chat_templates.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒêi·ªÅu ch·ªânh SFTTrainer\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh `SFTTrainer` v·ªõi c√°c tham s·ªë kh√°c nhau gi√∫p ƒëi·ªÅu khi·ªÉn qu√° tr√¨nh hu·∫•n luy·ªán tr·ªü n√™n hi·ªáu qu·∫£ h∆°n. C√°c th√¥ng s·ªë bao g·ªìm\n",
    "- S·ªë b∆∞·ªõc hu·∫•n luy·ªán (steps)\n",
    "- K√≠ch th∆∞·ªõc batch (batch size)\n",
    "- T·ªëc ƒë·ªô h·ªçc (learning rate)\n",
    "- Chi·∫øn l∆∞·ª£c ƒë√°nh gi√° m√¥ h√¨nh (evaluation strategy)\n",
    "\n",
    "Ngo√†i ra, c√≤n r·∫•t nhi·ªÅu th√¥ng s·ªë kh√°c, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m ·ªü [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh c√°c tham s·ªë n√†y d·ª±a tr√™n y√™u c·∫ßu c·ª• th·ªÉ v√† t√†i nguy√™n t√≠nh to√°n c·ªßa b·∫°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒêi·ªÅu ch·ªânh SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n k√≠ch th∆∞·ªõc dataset v√† th·ªùi l∆∞·ª£ng hu·∫•n luy·ªán mong mu·ªën\n",
    "    per_device_train_batch_size=4,  # ƒê·∫∑t theo dung l∆∞·ª£ng b·ªô nh·ªõ GPU c·ªßa b·∫°n\n",
    "    learning_rate=5e-5,  # Ph·ªï bi·∫øn cho qu√° tr√¨nh hu·∫•n luy·ªán c√≥ gi√°m s√°t\n",
    "    logging_steps=10,  # T·∫ßn su·∫•t ghi log c√°c metrics hu·∫•n luy·ªán\n",
    "    save_steps=100,  # T·∫ßn su·∫•t l∆∞u c√°c checkpoint m√¥ h√¨nh\n",
    "    evaluation_strategy=\"steps\",  # ƒê√°nh gi√° m√¥ h√¨nh theo c√°c kho·∫£ng th·ªùi gian\n",
    "    eval_steps=50,  # T·∫ßn su·∫•t ƒë√°nh gi√°\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # S·ª≠ d·ª•ng MPS cho hu·∫•n luy·ªán ƒë·ªô ch√≠nh x√°c h·ªón h·ª£p\n",
    "    hub_model_id=finetune_name,  # ƒê·∫∑t t√™n cho m√¥ h√¨nh c·ªßa b·∫°n\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: ü¶Å üêï cƒÉn ch·ªânh c√°c tham s·ªë SFTTrainer v·ªõi b·ªô d·ªØ li·ªáu b·∫°n ƒë√£ ch·ªçn.\n",
    "# V√≠ d·ª•, n·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng b·ªô `bigcode/the-stack-smol`, b·∫°n s·∫Ω c·∫ßn ch·ªçn c·ªôt `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hu·∫•n luy·ªán M√¥ h√¨nh\n",
    "\n",
    "V·ªõi trainer ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh, ch√∫ng ta c√≥ th·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh. Qu√° tr√¨nh hu·∫•n luy·ªán s·∫Ω bao g·ªìm\n",
    "- L·∫∑p qua b·ªô d·ªØ li·ªáu\n",
    "- T√≠nh to√°n loss\n",
    "- C·∫≠p nh·∫≠t c√°c tham s·ªë c·ªßa m√¥ h√¨nh ƒë·ªÉ gi·∫£m thi·ªÉu loss n√†y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "trainer.train()\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê∆∞a m√¥ h√¨nh l√™n Hugging Face Hub\n",
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p th√™m: Sinh vƒÉn b·∫£n v·ªõi m√¥ h√¨nh v·ª´a ƒë∆∞·ª£c hu·∫•n luy·ªán</h2>\n",
    "    <p>üêï S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ra ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª• ban ƒë·∫ßu.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√πng m·ªôt y√™u c·∫ßu\n",
    "\n",
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng chat\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Sinh ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª•."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê Ch√∫c m·ª´ng b·∫°n. B·∫°n ƒë√£ ho√†n th√†nh!\n",
    "\n",
    "B√†i t·∫≠p n√†y ƒë√£ cung c·∫•p h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc ƒë·ªÉ b·∫°n hu·∫•n luy·ªán ƒë∆∞·ª£c m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` s·ª≠ d·ª•ng `SFTTrainer`. B·∫±ng c√°ch l√†m theo c√°c b∆∞·ªõc n√†y, b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• c·ª• th·ªÉ hi·ªáu qu·∫£ h∆°n. N·∫øu b·∫°n mu·ªën ti·∫øp t·ª•c l√†m vi·ªác v·ªõi kh√≥a h·ªçc n√†y, ƒë√¢y l√† m·ªôt s·ªë b∆∞·ªõc b·∫°n c√≥ th·ªÉ th·ª≠:\n",
    "\n",
    "- Th·ª≠ notebook n√†y ·ªü m·ª©c ƒë·ªô kh√≥ h∆°n\n",
    "- Review PR c·ªßa h·ªçc vi√™n kh√°c\n",
    "- C·∫£i thi·ªán t√†i li·ªáu kh√≥a h·ªçc th√¥ng qua Issue ho·∫∑c PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
