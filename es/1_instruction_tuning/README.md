# Ajuste por Instrucciones (Instruction Tuning)

Este m√≥dulo te guiar√° en el proceso de ajuste por instrucciones de modelos de lenguaje. El ajuste por instrucciones implica adaptar modelos preentrenados a tareas espec√≠ficas mediante un entrenamiento adicional sobre conjuntos de datos espec√≠ficos para esas tareas. Este proceso ayuda a los modelos a mejorar su rendimiento en tareas espec√≠ficas.

En este m√≥dulo, exploraremos dos temas: 1) Plantillas de Chat y 2) Fine-tuning Supervisado

## 1Ô∏è‚É£ Plantillas de Chat

Las plantillas de chat estructuran las interacciones entre los usuarios y los modelos de IA, asegurando respuestas coherentes y contextualmente apropiadas. Estas plantillas incluyen componentes como los mensajes de sistema y mensajes basados en roles. Para m√°s informaci√≥n detallada, consulta la secci√≥n de [Plantillas de Chat](./chat_templates.md).

## 2Ô∏è‚É£ Fine-tuning Supervisado

El Fine-tuning supervisado (SFT) es un proceso cr√≠tico para adaptar modelos de lenguaje preentrenados a tareas espec√≠ficas. Implica entrenar el modelo en un conjunto de datos espec√≠fico para la tarea con ejemplos etiquetados. Para una gu√≠a detallada sobre el SFT, incluyendo pasos clave y mejores pr√°cticas, consulta la p√°gina de [Fine-tuning Supervisado](./supervised_fine_tuning.md).

## Cuadernos de Ejercicio

| T√≠tulo | Descripci√≥n | Ejercicio | Enlace | Colab |
|--------|-------------|-----------|--------|-------|
| Plantillas de Chat | Aprende a usar plantillas de chat con SmolLM2 y a procesar conjuntos de datos en formato chatml | üê¢ Convierte el conjunto de datos `HuggingFaceTB/smoltalk` al formato chatml <br> üêï Convierte el conjunto de datos `openai/gsm8k` al formato chatml | [Cuaderno](./notebooks/chat_templates_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/chat_templates_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"/></a> |
| Fine-tuning Supervisado | Aprende a afinar SmolLM2 utilizando el SFTTrainer | üê¢ Usa el conjunto de datos `HuggingFaceTB/smoltalk` <br> üêï Prueba el conjunto de datos `bigcode/the-stack-smol` <br> ü¶Å Selecciona un conjunto de datos para un caso de uso real | [Cuaderno](./notebooks/sft_finetuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"/></a> |

## Referencias

- [Documentaci√≥n de Transformers sobre plantillas de chat](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script para Fine-Tuning Supervisado en TRL](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
- [`SFTTrainer` en TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Papel de Optimizaci√≥n Directa de Preferencias](https://arxiv.org/abs/2305.18290)
- [Fine-Tuning Supervisado con TRL](https://huggingface.co/docs/trl/main/en/tutorials/supervised_finetuning)
- [C√≥mo afinar Google Gemma con ChatML y Hugging Face TRL](https://www.philschmid.de/fine-tune-google-gemma)
- [Fine-Tuning de LLM para generar cat√°logos de productos persas en formato JSON](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)
